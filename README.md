# Vis√£o geral
Este projeto prev√™ desligamento de funcion√°rios (employee churn) usando dados tabulares. O objetivo √© apoiar RH/People Analytics na redu√ß√£o de turnover, priorizando a√ß√µes preventivas em grupos com maior probabilidade de sa√≠da.

- Fonte de dados: Kaggle ‚Äì Employee Attrition Dataset
https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset

- Notebook principal: RotatividadeFuncionarios.ipynb

- Artefatos gerados: modelo_treinado_desligamento_funcionarios.pk (RandomForest)

# üß† Problema de neg√≥cio
Turnover impacta custos de recrutamento, treinamento e produtividade. Antecipar quem tem maior propens√£o a sair permite interven√ß√µes direcionadas (ex.: trilhas de carreira, revis√£o de pol√≠ticas de horas extras, benef√≠cios, mobilidade interna).

# üóÇÔ∏è Dados e dicion√°rio (resumo)
- A base tem 59.598 linhas e, inicialmente, 24 colunas (ap√≥s engenharia e codifica√ß√£o, 33 atributos). Exemplos de vari√°veis:

- Demogr√°ficas e de cargo: Idade, Genero, Cargo, Funcao, Escolaridade, Tamanho_Empresa

- Jornada e hist√≥rico: Anos_Empresa, Qtd_Anos_Trabalho, Qtd_Promocoes, Distancia_Casa, Hora_Extra, Trabalho_Remoto

- Percep√ß√µes: Equilibrio_Vida, Satisfacao, Desempenho, Reputacao_Empresa, Reconhecimento

- Remunera√ß√£o (binned): Faixa_Salarial (derivada de Salario_Mensal)

- Alvo (target): Situacao (0 = permaneceu / 1 = saiu)

### Distribui√ß√£o da vari√°vel alvo (original):

- Stayed: 31.260

- Left: 28.338
Ap√≥s balanceamento por under‚Äësampling, ficaram 28.338 observa√ß√µes em cada classe.

# üßπ Pipeline de prepara√ß√£o
- Renomea√ß√£o dos campos para portugu√™s e padroniza√ß√£o.

### Tratativa de inconsist√™ncias:

- Ajuste de Anos_Empresa quando Idade - Anos_Empresa < 18 ‚Üí Anos_Empresa = 1.

- Identifica√ß√£o de vari√°veis incoerentes (ex.: Qtd_Anos_Trabalho > Anos_Empresa em todas as linhas ‚Üí sinal para desconsiderar no modelo).

### Engenharia de atributos:

- Faixa_Salarial via binning de Salario_Mensal.

### Codifica√ß√£o de categorias:

- OrdinalEncoder para ordinais (Faixa_Salarial, Equilibrio_Vida, Satisfacao, Desempenho, Escolaridade, Cargo, Tamanho_Empresa, Reputacao_Empresa, Reconhecimento).

- OneHotEncoder para nominais (Genero, Funcao, Hora_Extra, Estado_Civil, Trabalho_Remoto, Oportunidade_Lideranca, Oportunidade_Inovacao).

### Total final: 33 atributos (category(1), float64(18), int32(9), int64(5)).

### Balanceamento do target: RandomUnderSampler (classes igualadas).

### Split treino/teste: 70%/30% (estratificado pelo balanceamento).

### Escalonamento: MinMaxScaler apenas nas preditoras (nunca no target).

# üîé Explorat√≥ria (EDA) ‚Äì o que foi analisado
Boxplots das vari√°veis num√©ricas para triagem de outliers.

Countplots segmentados por Situacao para vari√°veis categ√≥ricas (ex.: Hora_Extra, Trabalho_Remoto, Funcao, Estado_Civil).

Observa√ß√£o: conclus√µes causais n√£o s√£o assumidas; os gr√°ficos apoiam hip√≥teses para futuras an√°lises.

# ü§ñ Modelagem e avalia√ß√£o
Modelos comparados (ap√≥s o pipeline acima):

### Modelo	Acur√°cia (treino)	Acur√°cia (teste)
- Random Forest (tuned)	97,14%	74,52%
- SVM (RBF, C=5.0, coef0=0.5)	74,36%	72,52%
- KNN (k=7, leaf_size=30)	77,20%	65,67%

### Ajuste de hiperpar√¢metros (GridSearchCV)
- Random Forest
- Grid: n_estimators=[100,200,300], max_depth=[2,5,7,10,20], criterion=['gini','entropy'], max_features=['sqrt','log2',None], min_samples_split=[1,2,5], min_samples_leaf=[1,2,3]
- Melhor (cv): 74,13% ‚Ä¢ Melhores params: criterion='entropy', max_depth=20, max_features='log2', min_samples_split=2, min_samples_leaf=2, n_estimators=300
- Tempo: 1435,58s ‚Ä¢ Treinos: 810

### SVM (RBF)
- Melhor (cv): 72,36% ‚Ä¢ Melhores params: C=5.0, coef0=0.5
- Tempo: 664,13s ‚Ä¢ Treinos: 6

### KNN
- Melhor (cv): 65,36% ‚Ä¢ Melhores params: n_neighbors=7, leaf_size=30
- Tempo: 11,14s ‚Ä¢ Treinos: 9

Modelo final: Random Forest ajustado.
Exporta√ß√£o: joblib.dump(...) ‚Üí modelo_treinado_desligamento_funcionarios.pk
